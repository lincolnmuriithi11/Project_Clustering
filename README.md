# Zillow Project

## Purpose
This project aims to improve the original estimates of "logerror" by using clustering/binning methodologies.

The customer: Zillow data science team.

## Deliverables
     - A clearly named final notebook. This notebook will be what you present and should contain plenty of markdown    documentation and cleaned up code.
    -A README that explains what the project is, how to reproduce you work, and your notes from project planning.
    -A Python module or modules that automate the data acquisistion and preparation process. These modules should be imported and used in your final notebook.
## Data Science Pipeline

# Planning
- Hypotheses:
    - $H_0$: new features will have no effect on the log error
    - $H_a$: new features engineered using clustering will reduce logerror

- Target variable "logerror" 

# Acquire Data
- #### Acuired the Zillow data from the Sql database 
- #### Saved the data in a csv file
- #### Stored the data in a in a function as a dataframe 
- #### The original data has 52440 rows and 6 columns
# Data Preparation
- wrangle_zillow has all functions listed here
### Steps taken for a clean dataset
1. #### Adressed missing values by dropping them since they were less than 10% of the initial data 

2. #### In order to simulate an ordinary homebuyer I took care of the outliers by:
     - removing houses over 8000 sqfeet, below 70feet
     - removing houses costing over 1.8 million in tax dollar amount 
     - removing rows with houses over 8 bedrooms and 8 bathrooms 
     
3. #### Converted fips column to categorical and changed the names to county names for readability purposes 
     - Ventura for  "6111"
     - Orange for"6059
     - Los_Angeles for "6037"

4. #### Feature engineering:
     - converted max transaction date to  specific months 
     - converted year built into age of the property
     - added a feature price per bathroom price_bath = df.taxvaluedollarcnt/ df.bathroomcnt
     - engineered a feature price per sqft called price_sqft = df.taxvaluedollarcnt/calculatedfinishedsquarefeet
     - added a feature average price per region called df taxvaluedollarcnt_zone
     
5. #### Dropped many columns after using Kbest to find the best features to predict taxvaluedollarcnt and logerror
        using a function, more information on the data dictionary

6. #### Created a function that splits the data into train, validate and test dataframes

7. #### Created a function that that scaled the data for modeling purposes

8. #### Started off with 67 columns and 52000 rows and ended up with 17 columns and 49000 rows
## #Data Dictionary
        1. bathroomcnt = number of bathrooms. Used 'bathroomcnt' because in the last project it has a coeefficient of 50 with the taxdollarcnt.
        2. bedroomcnt = number of bedrooms. A feature that most single families tend to look at while home buying.
        
        3. latitude - to have an estimate of the location of the house
        4. longitude - combined with lattitude it shows housing location
        5. taxvaluedollarcnt = value of the home.
        6. logerror = the amount of error generated by zillow's ML model using natural log.
        7. transactiondate = date field indicating when the property was put on the market.
        8. regionid_zip = incorrect zip code
        9. county = name of county the property is from. This field came from the fips identifier in the 
        10. age = subtracted 2017 from yearbuilt
        11. county_Los_Angeles = dummied field indicating whether or not the propery is in Los Angeles County.
        12. county_Orange = dummied field indicating whether or not the propery is in Orange County.
        13. county_Ventura = dummied field indicating whether or not the propery is in Ventura County.
        14. age_bin = Binned field indicating how old the property is
        15. price_region_bin = bins indicating price per region(zipcode)
        16. price_bath = price per bathroom
        17. encoded counties LA Ventura and Orange
# Data Exploration
- Goal: Address questions generated during planning and preparation phases
    - Walkthrough_1 has the finalized version of data exploration

# Feature Selection
- Goal: a dataframe with the features to be used to build the model
    - Walkthrough_1 has the finalized version of feature creation and selection
    - By running Walkthrough_1, a csv file is generated with the finalized version of the dataframe used to create the regression model

# Modeling & Evaluation
- Goal: develop a regression model that performs better than a baseline
    - Walkthrough_2 has the finalized version of model selection and evaluation
